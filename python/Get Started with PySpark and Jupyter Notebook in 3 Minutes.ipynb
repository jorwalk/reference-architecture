{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apache Spark installation + ipython/jupyter notebook integration guide for macOS\n",
    "================================================================================\n",
    "\n",
    "Tested with Apache Spark 2.1.0, Python 2.7.13 and Java 1.8.0_112\n",
    "\n",
    "For older versions of Spark and ipython, please, see also [previous version of text](https://gist.github.com/ololobus/4c221a0891775eaa86b0/956c90bceef6424ef74cc68c4b8b1acd688e1c82).\n",
    "\n",
    "\n",
    "Install Java Development Kit\n",
    "----------------------------\n",
    "Download and install it from [oracle.com](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html)\n",
    "\n",
    "Add following code to your e.g. `.bash_profile`\n",
    "```bash\n",
    "# For Apache Spark\n",
    "if which java > /dev/null; then export JAVA_HOME=$(/usr/libexec/java_home); fi\n",
    "```\n",
    "\n",
    "Install Apache Spark\n",
    "--------------------\n",
    "You can use Mac OS package manager Brew ([http://brew.sh/](http://brew.sh/))\n",
    "```shell\n",
    "brew update\n",
    "brew install scala\n",
    "brew install apache-spark\n",
    "```\n",
    "\n",
    "Set up env variables\n",
    "--------------------\n",
    "Add following code to your e.g. `.bash_profile`\n",
    "```bash\n",
    "# For a ipython notebook and pyspark integration\n",
    "if which pyspark > /dev/null; then\n",
    "  export SPARK_HOME=\"/usr/local/Cellar/apache-spark/2.1.0/libexec/\"\n",
    "  export PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/build:$PYTHONPATH\n",
    "  export PYTHONPATH=$SPARK_HOME/python/lib/py4j-0.10.4-src.zip:$PYTHONPATH\n",
    "fi\n",
    "```\n",
    "\n",
    "You can check `SPARK_HOME` path using following brew command\n",
    "```\n",
    "$ brew info apache-spark\n",
    "apache-spark: stable 2.1.0, HEAD\n",
    "Engine for large-scale data processing\n",
    "https://spark.apache.org/\n",
    "/usr/local/Cellar/apache-spark/2.1.0 (1,312 files, 213.9M) *\n",
    "  Built from source on 2017-02-13 at 00:58:12\n",
    "From: https://github.com/Homebrew/homebrew-core/blob/master/Formula/apache-spark.rb\n",
    "```\n",
    "\n",
    "Also check `py4j` version and subpath, it mau differ from version to version.\n",
    "\n",
    "\n",
    "Ipython profile\n",
    "----------------------\n",
    "\n",
    "Since [profiles are not supported](http://jupyter.readthedocs.io/en/latest/migrating.html#since-jupyter-does-not-have-profiles-how-do-i-customize-it) in `jupyter` and now you can see following deprecation warning\n",
    "```shell\n",
    "$ ipython notebook --profile=pyspark\n",
    "[TerminalIPythonApp] WARNING | Subcommand `ipython notebook` is deprecated and will be removed in future versions.\n",
    "[TerminalIPythonApp] WARNING | You likely want to use `jupyter notebook` in the future\n",
    "[W 01:45:07.821 NotebookApp] Unrecognized alias: '--profile=pyspark', it will probably have no effect.\n",
    "```\n",
    "It seems that it is not possible to run various custom startup files as it was with `ipython` profiles. Thus, the easiest way will be to run `pyspark` init script at the beginning of your notebook manually or follow [alternative way](#alternatively).\n",
    "\n",
    "Run ipython\n",
    "-----------\n",
    "```\n",
    "$ jupyter-notebook\n",
    "```\n",
    "\n",
    "Initialize `pyspark`\n",
    "```ipython\n",
    "In [1]: import os\n",
    "        execfile(os.path.join(os.environ[\"SPARK_HOME\"], 'python/pyspark/shell.py'))\n",
    "Out[1]: <pyspark.context.SparkContext at 0x10a982b10>\n",
    "```\n",
    "\n",
    "`sc` variable should be available\n",
    "```ipython\n",
    "In [2]: sc\n",
    "Out[2]: <pyspark.context.SparkContext at 0x10a982b10>\n",
    "```\n",
    "\n",
    "Alternatively\n",
    "-------------\n",
    "\n",
    "You can also force `pyspark` shell command to run ipython web notebook instead of command line interactive interpreter. To do so you have to add following env variables:\n",
    "```shell\n",
    "export PYSPARK_DRIVER_PYTHON=jupyter\n",
    "export PYSPARK_DRIVER_PYTHON_OPTS=notebook\n",
    "```\n",
    "and then simply run\n",
    "```shell\n",
    "$ pyspark\n",
    "```\n",
    "which will open a web notebook with `sc` available automatically.\n",
    "\n",
    "\n",
    "<a>![Analytics](https://mc.yandex.ru/watch/42761284)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
