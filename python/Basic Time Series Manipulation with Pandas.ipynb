{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This basic introduction to time series data manipulation with pandas should allow you to get started in your time series analysis. Specific objectives are to show you how to:\n",
    "\n",
    "* create a date range\n",
    "* work with timestamp data\n",
    "* convert string data to a timestamp\n",
    "* index and slice your time series data in a data frame\n",
    "* resample your time series for different time period aggregates/summary statistics\n",
    "* compute a rolling statistic such as a rolling average\n",
    "* work with missing data\n",
    "* understand the basics of unix/epoch time\n",
    "* understand common pitfalls of time series data analysis\n",
    "\n",
    "First import the libraries we’ll be working with and then use them to create a date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "date_rng = pd.date_range(start='1/1/2018', end='1/08/2018', freq='H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(date_rng[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s create an example data frame with the timestamp data and look at the first 15 elements:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(date_rng, columns=['date'])\n",
    "df['data'] = np.random.randint(0,100,size=(len(date_rng)))\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to do time series manipulation, we’ll need to have a date time index so that our data frame is indexed on the timestamp.\n",
    "\n",
    "Convert the data frame index to a datetime index then show the first elements:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df['datetime'] = pd.to_datetime(df['date'])\n",
    "df = df.set_index('datetime')\n",
    "df.drop(['date'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if our ‘time’ stamps in our data are actually string type vs. numerical? Let’s convert our date_rng to a list of strings and then convert the strings to timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_date_rng = [str(x) for x in date_rng]\n",
    "string_date_rng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert the strings to timestamps by inferring their format, then look at the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_date_rng = pd.to_datetime(string_date_rng, infer_datetime_format=True)\n",
    "timestamp_date_rng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what about if we need to **convert a unique string format**?\n",
    "\n",
    "Let’s create an arbitrary list of dates that are strings and convert them to timestamps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_date_rng_2 = ['June-01-2018', 'June-02-2018', 'June-03-2018']\n",
    "timestamp_date_rng_2 = [datetime.strptime(x,'%B-%d-%Y') for x in string_date_rng_2]\n",
    "timestamp_date_rng_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does it look like if we put this into a data frame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(timestamp_date_rng_2, columns=['date'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going back to our original data frame, let’s look at the data by parsing on timestamp index:\n",
    "\n",
    "Say we just want to see data where the date is the 2nd of the month, we could use the index as per below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.index.day == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also directly call a date that we want to look at via the index of the data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['2018-01-03']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about **selecting data between certain dates**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['2018-01-04':'2018-01-06']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic data frame that we’ve populated gives us data on an hourly frequency, but we can resample the data at a different frequency and specify how we would like to compute the summary statistic for the new sample frequency. We could take the min, max, average, sum, etc., of the data at a daily frequency instead of an hourly frequency as per the example below where we compute the daily average of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.resample('D').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about **window statistics such as a rolling mean or a rolling sum**?\n",
    "\n",
    "Let’s create a new column in our original df that computes the rolling sum over a 3 window period and then look at the top of the data frame:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rolling_sum'] = df.rolling(3).sum()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this is computing correctly and that it only starts having valid values when there are three periods over which to look back.\n",
    "\n",
    "This is a good chance to see how we can do **forward or backfilling of data when working with missing data values**.\n",
    "\n",
    "Here’s our df but with a new column that takes the rolling sum and backfills the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rolling_sum_backfilled'] = df['rolling_sum'].fillna(method='backfill')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s an example of a time t that is in Epoch time and converting unix/epoch time to a regular time stamp in UTC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_t = 1529272655\n",
    "real_t = pd.to_datetime(epoch_t, unit='s')\n",
    "real_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I wanted to convert that time that is in UTC to my own time zone, I could simply do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_t.tz_localize('UTC').tz_convert('US/Pacific')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a **few tips to keep in mind and common pitfalls to avoid when working with time series data**:\n",
    "\n",
    "* **Check for discrepancies** in your data that may be caused by region specific time changes like daylight savings time.\n",
    "* **Keep track of time zones** meticulously — let others going through your code know what time zone your data is in, and think about converting to UTC or a standardized value in order to keep your data standardized.\n",
    "* Missing data can occur frequently — make sure you **document your cleaning rules** and think about not backfilling information you wouldn’t have been able to have at the time of a sample.\n",
    "* Remember that as you resample your data or fill in missing values, you’re losing a certain amount of information about your original data set. I’d suggest **keeping track of all of your data transformations** and tracking the root cause of your data issues.\n",
    "* When you resample your data, the best method (mean, min, max, sum, etc.) will be dependent on the kind of data you have and how it was sampled. **Be thoughtful about how you resample your data** for your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
